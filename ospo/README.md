# Reproduce Guide

The following section provides instructions for reproducing the full OSPO framework, starting from generating the dataset from scratch. In OSPO framework, we generate synthetic preference data and train the LLM backbone using SimPO based on the generated data.

1. Configure the files `step1.yaml` to `step4.yaml` located in the `./configs` directory.
- The `data_path` field is optional and does not need to be specified.
- The `max_len` field specifies the number of generated samples per category; the total number of samples will be `max_len * 4`.
2. Run the script. 
```bash
bash scripts/run.sh
```
We uploaded the example data generated by the OSPO framework in the `./examples` directory.</br>(If you specifically need a full dataset at an intermediate step, please contact the authors.)

🧐 _If you want to run each step individually, use the commands below._

## STEP 1. Initial Prompt Generation
> **Note:** You must run the script separately for each category.
```bash
python ospo/step1.py --category ${CATEGORY_NAME}
```
## STEP 2. Hard Preference Pair Generation
#### 2-1. Negative / Dense Text Generation  
```bash
python ospo/step2_1.py --cfg_path configs/step2_1.yaml
```
#### 2-2. Image Generation
```bash
python ospo/step2_2.py --cfg_path configs/step2_2.yaml
```
## STEP 3. Filtering and Selection
#### 3-1. VQA Question / Result Generation  
```bash
python ospo/step3_1.py --cfg_path configs/step3_1.yaml
```
#### 3-2. Self-VQA based Filtering and Preference Pair (=training data) Construction
```bash
python ospo/step3_2.py --cfg_path configs/step3_2.yaml
```
## Step 4. Training
> **Note:** The final training dataset constructed from Step 4 is available at `./examples/step4/train_data_mode_negative.json`.
```bash
python ospo/step4.py --cfg_path configs/step4.yaml
```
